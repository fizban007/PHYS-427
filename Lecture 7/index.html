<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content=
      "width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Computational Physics Lecture 7</title>
    <link rel="stylesheet" href="../dist/reset.css">
    <link rel="stylesheet" href="../dist/reveal.css">
    <link rel="stylesheet" href="../dist/theme/serif.css"
      id="theme">
    <!-- <link rel="stylesheet" href="./dist/theme/night.css" id="theme"> -->
    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href=
      "../plugin/highlight/monokai.css" id="highlight-theme">
    <link rel="stylesheet" href=
      "../css/style.css">
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <h2>Numerical Integration</h2>
        </section>

        <section>
          <h2>Numerical Integration</h2>
          <p>We discussed an adaptive scheme of evaluating definite integrals
          numerically.</p>
          $$
          \begin{align}
          S_1 &= \frac{1}{2}\left[f(a) + f(b)\right](b - a) \\
          S_2 &= \frac{1}{2}S_1 + \frac{1}{2}(b - a)\sum_{i=1}^1 f(x_i) \\
          S_3 &= \frac{1}{2}S_2 + \frac{1}{4}(b - a)\sum_{i=1}^2 f(x_i) \\
          \dots
          \end{align}
          $$
        </section>

        <section>
          <h2>Numerical Integration</h2>
          <p>From the sequence of trapezoidal approximations $S_n$, we can form
          the Simpson approximations:</p>
          $$
          S'_n = \frac{4}{3}S_n - \frac{1}{3}S_{n-1}
          $$
          <p>which are a lot more accurate than the trapezoidal approximations.</p>
        </section>

        <section>
          <h2>Romberg Integration</h2>
          <p>Forming $S'_n$ cancels out the approximation error at order $h^2$.
          Can we do better than this?</p>
          <br>
          <p>Yes. The procedure is a an algorithm called Romberg integration.</p>
        </section>

        <section>
          <h2>Romberg Integration</h2>
          <p>Let's start by renaming our values in a suggestive way:</p>
          <br>
          Define $R_{n,1} = S_n$, $R_{n, 2} = S'_n$.
          <br><br>
          <p>$R_{n,1}$ is the trapezoidal approximation to the integral, which
          has error of order $\varepsilon_{n,1} = O(h_n^2)$.</p>
          <p>$R_{n,2}$ is the Simpson approximation to the integral, which
          has error of order $\varepsilon_{n,2} = O(h_n^4)$.</p>
        </section>

        <section>
          <h2>Romberg Integration</h2>
          <p>Let's write the last error as $\varepsilon_{n,2} = c_2h_n^4 + O(h_n^6)$. What
          linear combination do I need to form in order to cancel the 4th order error?</p>
          <div class="fragment">
            <p>Let $I$ be the exact integral we want to find. Then we can write:</p>
            $$
            \begin{align}
            I &= R_{n,2} + c_2h_n^4 + O(h_n^6) = R_{n-1,2} + c_2h_{n-1}^4 + O(h_{n-1}^6) \\
            &= R_{n-1,2} + 16c_2h_n^4 + O(h_n^6)
            \end{align}
            $$
            $$
            c_2h_n^4 = \frac{1}{15}(R_{n,2} - R_{n-1,2}) + O(h_n^6)
            $$
            <p>This is actually just the 4th order error estimate for Simpson
            estimation that we discussed last time.</p>
          </div>
        </section>

        <section>
          <h2>Romberg Integration</h2>
          <p>Now we can define the higher order version of $R_{n,2}$:</p>
          $$
          R_{n,3} = R_{n,2} + \frac{1}{15}\left(R_{n,2} - R_{n-1,2}\right)
          $$
          <p>You can think of $R_{n,3}$ as a new approximation to the integral
          that has error of order $\varepsilon_{n,3} = O(h_n^6)$.</p>
          <p>The error on $R_{n,3}$ can be estimated as:</p>
          $$
          \varepsilon_{n,3} = \frac{1}{63}\left(R_{n,3} - R_{n-1,3}\right) + O(h_n^8)
          $$
        </section>

        <section>
          <h2>Romberg Integration</h2>
          <p>This general procedure can be repeated for up to $n$ times. At any
          refinement level $n$, the general $R_{n,m}$ is the estimate that is
          accurate to order $h_n^{2m}$.</p>
          $$
          R_{n,m+1} = R_{n,m} + \frac{1}{4^m - 1}\left(R_{n,m} - R_{n-1,m}\right)
          $$
          <p>The error for this estimate will be:</p>
          $$
          \varepsilon_{n,m+1} = \frac{1}{4^{m+1} - 1}\left(R_{n,m+1} - R_{n-1,m+1}\right) + O(h_n^{2m+4})
          $$
        </section>

        <section>
          <h2>Romberg Integration</h2>
          $$
          R_{n,m+1} = R_{n,m} + \frac{1}{4^m - 1}\left(R_{n,m} - R_{n-1,m}\right)
          $$
          <img src="romberg.png" alt="integral" width="60%">
        </section>

        <section>
          <h2>Romberg Integration</h2>
          <p>Romberg integration is an example of a more general idea called <em>Richardson extrapolation</em>.
          The idea is to extrapolate existing low-order estimates to construct
          higher order estimates of the target result.</p>
          <p>We will encounter Richardson extrapolation again when dealing with ODEs.</p>
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>So far, we have restricted our integral estimates on evenly
            spaced $\{x_i\}$. This set of integration rules are collectively called <em>Newton-Cotes</em> formulae.</p>
          <p>If we are allowed to play with the spacing between points $x_i$
          where the functions is evaluated, we can potentially achieve much
            faster convergence. The points $x_i$ are called <em>abscissas</em>.</p>
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>Given a set of abscissas $x_i$ and weights $w_i$, the integral can
          be approximated as:</p>
          $$
          \int_a^b f(x)\,dx \approx \sum_{i=0}^{n-1} w_i f(x_i)
          $$
          <p>The nontrivial problem is to locate $x_i$ and calculate $w_i$.</p>
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>The classical Gauss-Legendre case uses roots of the $n$th Legendre
          polynomial $P_n(x)$ for the abscissas $x_i$.</p>
          $$
          \int_{-1}^1 f(x)\,dx \approx \sum_{i=0}^{n-1} w_i f(x_i)
          $$
          <p>where $x_i$ are the $n$ solutions of $P_n(x) = 0$.</p>
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <img src="legendre-polynomials.png" alt="integral" width="70%">
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>The Gauss-Legendre weights are defined to be:</p>
          $$
          w_i = \frac{2}{(1 - x_i^2)[P'_n(x_i)]^2}
          $$
          <p>where $P'_n(x_i)$ is the first derivative of $P_n(x)$ evaluated at
          the abscissas $x_i$.</p>
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>Weights and abscissas for $N=10$ Gauss-Legendre quadrature:</p>
          <img src="legendre-weights.png" alt="integral" width="50%">
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>Weights and abscissas for $N=10$ Gauss-Legendre quadrature:</p>
          <ul>
            <li>$x_0 = -0.9739065285171717, \quad w_0 = 0.0666713443086881$</li>
            <li>$x_1 = -0.8650633666889845, \quad w_1 = 0.1494513491505806$</li>
            <li>$x_2 = -0.6794095682990244, \quad w_2 = 0.2190863625159821$</li>
            <li>$x_3 = -0.4333953941292472, \quad w_3 = 0.2692667193099963$</li>
            <li>$x_4 = -0.1488743389816312, \quad w_4 = 0.2955242247147529$</li>
            <li>$x_5 = -x_4, \quad w_5 = w_4$</li>
            <li>$x_6 = -x_3, \quad w_6 = w_3$</li>
            <li>$x_7 = -x_2, \quad w_7 = w_2$</li>
            <li>$x_8 = -x_1, \quad w_8 = w_1$</li>
            <li>$x_9 = -x_0, \quad w_9 = w_0$</li>
          </ul>
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>Note that Gauss-Legendre quadrature formula works on the interval
          $[-1, 1]$. For an arbitrary interval $[a, b]$, you will need to map
          $x$ to $[-1, 1]$:</p>
          $$
          x = \frac{1}{2}(b - a)x' + \frac{1}{2}(b + a)
          $$
          <p>So that:</p>
          $$
          \int_a^b f(x)\,dx = \frac{1}{2}(b - a)\int_{-1}^1 f(x')\,dx'
          \approx \frac{1}{2}(b - a)\sum_{i=0}^{n-1}w_i f(x'_i)
          $$
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>Why does Gauss quadrature work?</p>
          <div class="fragment">
            <p>In essence, Gauss quadrature is using a degree $2n - 1$
            polynomial to approximate the function $f(x)$. For any $f(x)$ that
            can be written as a polynomial of order $<2n - 1$, Gauss quadrature
            gives the exact value.</p>
          </div>
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>$x_i$ are chosen to be the roots of a series of orthogonal
          polynomials $p_n(x)$. Orthogonal means $\int_a^b p_n(x)p_m(x) = 0$ if $n\neq m$. Legendre
          polynomials are orthogonal.</p>
          <p>We approximate our function $f(x)$ as an order $2n - 1$ polynomial:</p>
          $$
          f(x) \approx p_n(x)q(x) + r(x)
          $$
          <p>where $q(x)$ and $r(x)$ are polynomials of order $n - 1$. Since
          $p_n(x)$ is orthogonal to all $p_m(x)$ where $m < n$, and $q(x)$ can
          be written as combinations of $p_m(x)$, the integral:</p>
          $$
          \int_a^b f(x)\,dx \approx \int_a^b [p_n(x)q(x) + r(x)]\,dx = \int_a^b r(x)\,dx
          $$
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>Furthermore, if $x_i$ are roots of $p_n(x)$, then we have</p>
          $$
          f(x_i) \approx p_n(x_i)q(x_i) + r(x_i) = r(x_i)
          $$
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>Given $n$ and $x_i$, we can form the
          so-called <em>Lagrange interpolation polynomials</em>:</p>
          $$
          \ell_i(x) = \prod_{\substack{m=0\dots n-1 \\ m\neq i}}\frac{(x - x_m)}{(x_i - x_m)}
          $$
          <p>These polynomial have order $n - 1$, and have the property that
          $\ell_i(x_k) = \delta_{ik}$. We can write $r(x)$ as such an interpolation polynomial:</p>
          $$
          r(x) = \sum_{i=0}^{n-1}r(x_i)\ell_i(x),\quad r(x_k) = \sum_{i=0}^{n-1}r(x_i)\delta_{ik} = r(x_i)
          $$
          <p>This is a unique representation of $r(x)$.</p>
        </section>

        <section>
          <h2>Gauss Quadrature</h2>
          <p>Now we can write the Gauss quadrature as:</p>
          $$
          \int_a^b f(x)\,dx \approx \int_a^b [p_n(x)q(x) + r(x)]\,dx = \int_a^b \sum_{i=0}^{n-1}r(x_i)\ell_i(x)\,dx
          $$
          <p>Remember that $f(x_i) \approx r(x_i)$. Therefore we have:</p>
          $$
          \int_a^b f(x)\,dx \approx \sum_{i=0}^{n-1}f(x_i)\int_a^b\ell_i(x)\,dx = \sum_{i=0}^{n-1}w_if(x_i)
          $$
          <p>This approximation becomes exact if $f(x)$ is a polynomial of order $<2n - 1$.</p>
        </section>

      </div>
    </div>
    <!-- <script src="js/head.min.js"></script> -->
    <!-- <script>
         head.js(
         "vendor/jquery.min.js",
         // "vendor/three.js/build/three.min.js",
         // "vendor/three.js/examples/js/controls/OrbitControls.js",
         /* "vendor/socket.io-client/dist/socket.io.js", */
         // "vendor/THREE.MeshLine.js",
         /* "vendor/dat.gui.min.js",*/
         "vendor/EventEmitter.js",
         // "js/samples.js",
         );
         </script> -->
    <script src="../dist/reveal.js"></script>
    <script src="../plugin/math/math.js"></script>
    <script src="../plugin/notes/notes.js"></script>
    <script src="../plugin/markdown/markdown.js"></script>
    <script src="../plugin/highlight/highlight.js"></script>

    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        transition: "fade",
        slideNumber: true,
        history: true,
        center: true,
        width: "100%",
        height: "100%",
        disableLayout: false,
        navigationMode: "default",
        // minScale: 1,
        // maxScale: 1,
        margin: 0.2,
        padding: 0,
        hash: true,
        math: {
          mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          // pass other options into `MathJax.Hub.Config()`
          TeX: { Macros: { RR: "{\\bf R}" } }
        },
        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ]
      });
      Reveal.configure({
        keyboard: {
          81: null, // Do not respond to Q
          // 32: null, // Do not respond to space
        }
      });
      // Reveal.addEventListener("slidechanged", function(event) {
      //   var foot1 = document.getElementById("footer1");
      //   var foot2 = document.getElementById("footer2");
      //
      //   if (Reveal.getIndices().h === 0) {
      //     foot1.style.display = "none";
      //     foot2.style.display = "none";
      //   } else {
      //     foot1.style.display = "block";
      //     foot2.style.display = "block";
      //   }
      // });
      //
    </script>
  </body>
</html>
